|  
  webserverSecretKey=''
  fernetKey=''
  executor=KubernetesExecutor;
  ingress='
  enabled: true
  web:
    hosts:
      - web2.fenrir-k8s.openshift.sdntest.qubership.org
  flower:
    hosts:
      - flower2.fenrir-k8s.openshift.sdntest.qubership.org
  ';
  customPreinstallJob='
  enabled: true
  resources: {}
  env: []
  serviceAccount:
    create: false
  role:
    create: false
  command: null
  args:
    - python
    - /bin/createdb.py
  extraSecrets:
    postgres-conn:
      stringData: |
        POSTGRES_HOST: {{ .Values.data.metadataConnection.host }}
        POSTGRES_PORT: "{{ .Values.data.metadataConnection.port }}"
        DB_NAME: {{ .Values.data.metadataConnection.db }}
        DB_USER: {{ .Values.data.metadataConnection.user }}
        POSTGRES_PASSWORD: {{ .Values.data.metadataConnection.pass }}
        POSTGRES_ADMIN_USER: postgres
        POSTGRES_ADMIN_PASSWORD: ''
  extraEnvFrom: |
    - secretRef:
        name: 'postgres-conn'
  ';
  extraSecrets='
  "{{ .Release.Name }}-airflow-s3connections":
    stringData: >
      AIRFLOW_CONN_TEST_S3:
      'aws:///?aws_access_key_id=''&aws_secret_access_key=''endpoint_url=http%3A%2F%2Fminio.qa-kubernetes.openshift.sdntest.qubership.org%3A80&region_name=eu-central-1'
  ';
  extraEnvFrom=- secretRef:
      name: '{{ .Release.Name }}-airflow-s3connections';
  data='
  metadataSecretName: ~
  brokerUrlSecretName: ~   
  metadataConnection:
    user: airflowdb
    pass: ''
    host: pg-patroni.postgres.svc
    port: "5432"
    db: airflow_regr
    sslmode: disable
    protocol: postgresql
  brokerUrl: redis://default:airflow@airflow.redis.svc:6379/2
  ';
  workers='
  replicas: 1
  resources:
    limits:
      cpu: 2000m
      memory: 2Gi
    requests:
      cpu: 1500m
      memory: 1.5Gi
  terminationGracePeriodSeconds: 60
  command: null
  persistence:
    enabled: false
    size: 5Gi
    storageClassName: local-path
  kerberosSidecar:
    enabled: false
  ';
  webserver='
  replicas: 1
  resources:
    requests:
      cpu: 1000m
      memory: 1Gi
    limits:
      cpu: 1500m
      memory: 1.5Gi    
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: user
    password: ''
  ';
  platformAirflowMonitoring=true;
  serviceMonitor='
  enabled: true
  selector:
    app.kubernetes.io/component: monitoring
  path: /admin/metrics
  interval: 30s
  ';
  prometheusRule='
  enabled: true
  kubeAlerts: true
  additionalLabels:
    app.kubernetes.io/component: monitoring
  groups: []
  ';
  statsd='
  enabled: true
  securityContexts:
    pod:
      runAsUser: 50000
      runAsNonRoot: true
      fsGroup: 50000
      seccompProfile:
        type: RuntimeDefault
  ';
  serviceMonitorStatsd='
  enabled: true
  ';
  ESCAPE_SEQUENCE=true;
  airflowLocalSettings={{ .Files.Get "nc_files/nc_platform_logging_config.py" }};
  config='
  webserver:
    expose_config: "True"
  api:
    auth_backend: airflow.api.auth.backend.basic_auth
  logging:
    remote_logging: "True"
    remote_base_log_folder: s3://airflow/
    remote_log_conn_id: test_s3
    encrypt_s3_logs: "False"
    colored_console_log: "False"
    nc_logging_type: stdoutfilesystem
    task_log_reader: task
    audit_log_level: INFO
    logging_config_class: airflow_local_settings.NC_DEFAULT_LOGGING_CONFIG
    task_log_prefix_template: "[DAG_ID]:'{{ \"{{ ti.dag_id }}\" }}' [TASK_ID]:'{{
      \"{{ ti.task_id }}\" }}' [TIMESTAMP]:'{{ \"{{ ts }}\" }}' [TRY_NUMBER]:'{{
      \"{{ ti.try_number }}\" }}'"
  ';
  scheduler='
  replicas: 1
  resources:
    limits:
      cpu: 1500m
      memory: 1.5Gi
    requests:
      cpu: 800m
      memory: 1Gi
  ';
  images='
  airflow:
    pullPolicy: Always
  flower:
    pullPolicy: Always
  ';
  airflowIntegrationTests='
  enabled: false
  ';    
  statusProvisioner='
  enabled: true
  lifetimeAfterCompletion: 250
  ';   
